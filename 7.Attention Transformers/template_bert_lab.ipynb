{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OleksiiLatypov/Practical_Deep_Learning_with_PyTorch/blob/main/week7/template_bert_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Transformers: BERT**\n",
        "\n",
        "Hi! In this lab, you will learn how to use BERT (**Bidirectional Encoder Representations from Transformers**) model for a quotes classification task.\n",
        "\n",
        "**GPU** is recomended for this assignment. `Runtime` -> `Change runtime type` -> `GPU`\n",
        "\n",
        "**Instructions**\n",
        "- Write code in the space indicated with `### START CODE HERE ###`\n",
        "- Do not use loops (for/while) unless instructions explicitly tell you so. Parallelization in Deep Learning is key!\n",
        "- If you get stuck, ask for help in Slack or DM `@DRU Team`\n",
        "\n",
        "**You will learn**\n",
        "- How to build a custom BERT transformer\n",
        "    - How to preprocess text dataset for BERT model\n",
        "    - How to create a custom PyTorch dataset\n",
        "    - How to train and evaluate transformer model for a classification NLP task\n",
        "    - How to visualize the results using TensorBoard"
      ],
      "metadata": {
        "id": "kOL39he2wgBp-gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download data**"
      ],
      "metadata": {
        "id": "Oux1PSRHyJnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "wget.download('https://dru.fra1.digitaloceanspaces.com/DL_pytorch/datasets/07_attention_transformers/Bert/Quotes_dataset.csv')"
      ],
      "metadata": {
        "id": "HBzJzuuOyLeJ",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:23:45.443832Z",
          "iopub.execute_input": "2024-07-17T10:23:45.444261Z",
          "iopub.status.idle": "2024-07-17T10:23:58.638261Z",
          "shell.execute_reply.started": "2024-07-17T10:23:45.444228Z",
          "shell.execute_reply": "2024-07-17T10:23:58.637189Z"
        },
        "trusted": true,
        "outputId": "a6b22f7e-9a41-4420-8120-a3927f2a2bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: wget in /opt/conda/lib/python3.10/site-packages (3.2)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Quotes_dataset (1).csv'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import packages**\n",
        "\n",
        "Here we will import our regular packages with the addition of [transformers](https://huggingface.co/docs/transformers/index), which provides APIs to download and train state-of-the-art pretrained models quickly. In this lab, we will use a pre-trained model like `BertModel` and `BertTokenizer` for the tokenization task."
      ],
      "metadata": {
        "id": "hmXfKT-8yM4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "!pip install transformers==4.17.0\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "metadata": {
        "id": "_Y3qTJxawsga",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:23.091942Z",
          "iopub.execute_input": "2024-07-17T10:24:23.092718Z",
          "iopub.status.idle": "2024-07-17T10:24:35.209201Z",
          "shell.execute_reply.started": "2024-07-17T10:24:23.092674Z",
          "shell.execute_reply": "2024-07-17T10:24:35.208237Z"
        },
        "trusted": true,
        "outputId": "9c8050a1-f227-4800-b315-7bd0c9a78716"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers==4.17.0 in /opt/conda/lib/python3.10/site-packages (4.17.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (0.23.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (2.32.3)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (0.1.1)\nRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.17.0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.17.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.17.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.17.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.17.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.17.0) (2024.7.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.17.0) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.17.0) (1.4.2)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing and visualizations**\n",
        "\n",
        "For our dataset, we will be using the [Quotes dataset](https://www.kaggle.com/abdokamr/good-reads-quotes) from [Kaggle](https://www.kaggle.com). This dataset contains ~3000 quotes from each quote class (quotes of death, quotes of humor, etc.). We will use just a sample of the original dataset with 5 classes. Our task will be to classify the quote tag by text."
      ],
      "metadata": {
        "id": "gW4v3hphyVBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "Eagh2GBSNudG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Quotes_dataset.csv')\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "h85TUUA-qQhG",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:39.272963Z",
          "iopub.execute_input": "2024-07-17T10:24:39.273343Z",
          "iopub.status.idle": "2024-07-17T10:24:39.337926Z",
          "shell.execute_reply.started": "2024-07-17T10:24:39.273313Z",
          "shell.execute_reply": "2024-07-17T10:24:39.337005Z"
        },
        "trusted": true,
        "outputId": "39a34796-c459-41cd-b0d2-1e1bef9564b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 50,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              quotes              tag\n0  To the well-organized mind, death is but the n...  quotes_of_death\n1  I wish it need not have happened in my time,\" ...  quotes_of_death\n2  I'm the one that's got to die when it's time f...  quotes_of_death\n3  The fear of death follows from the fear of lif...  quotes_of_death\n4  I DON'T CARE!\" Harry yelled at them, snatching...  quotes_of_death",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quotes</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>To the well-organized mind, death is but the n...</td>\n      <td>quotes_of_death</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I wish it need not have happened in my time,\" ...</td>\n      <td>quotes_of_death</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm the one that's got to die when it's time f...</td>\n      <td>quotes_of_death</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The fear of death follows from the fear of lif...</td>\n      <td>quotes_of_death</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I DON'T CARE!\" Harry yelled at them, snatching...</td>\n      <td>quotes_of_death</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization\n",
        "\n",
        "Let's visualize how many quotes from each class we have:"
      ],
      "metadata": {
        "id": "JGqeWTtksFq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "class_counts = data.tag.value_counts()\n",
        "plt.bar(class_counts.index, class_counts.to_list())\n",
        "plt.xticks(np.arange(5), data[\"tag\"].unique())\n",
        "plt.xlabel('Tag class', fontweight='bold', fontsize=14.0)\n",
        "plt.ylabel('Count', fontweight='bold', fontsize=14.0 )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hJninhOTsKs_",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:41.163630Z",
          "iopub.execute_input": "2024-07-17T10:24:41.164286Z",
          "iopub.status.idle": "2024-07-17T10:24:41.444616Z",
          "shell.execute_reply.started": "2024-07-17T10:24:41.164254Z",
          "shell.execute_reply": "2024-07-17T10:24:41.443702Z"
        },
        "trusted": true,
        "outputId": "03b018a8-3b58-423d-af5c-b1a45b9431c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config\n",
        "\n",
        "In `Config` class, we will define standard hyperparameters for training. There are also a few additional hyperparameters: <br><br>\n",
        "\n",
        "**Model Config**\n",
        "- **model_name** - is a case-sensitive BERT model, which makes a difference between 'Hello' and 'hello'.\n",
        "- **max_len** - specifies the length of the tokenized text\n",
        "- **hidden_size** - is the number of hidden units in the feedforward-network\n",
        "\n",
        "**Data Preparation**\n",
        "- **test_fraction** - the fraction of the whole dataset that will be used for the final evaluation\n",
        "- **validation_fraction** - the fraction of the entire dataset that will be used for validating model performance during training\n",
        "- **num_workers** - denotes the number of processes that generate batches in parallel\n",
        "- **classes** - the names of the tags that we will classify\n",
        "- **tags_map** - is a dict with classes names and their encoded labels\n",
        "- **logdir** - is the directory you will create data to visualize in TensorBoard.\n"
      ],
      "metadata": {
        "id": "sCfbXjjWKcMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[cls] Config\n",
        "\n",
        "class Config:\n",
        "\n",
        "    # Model Config\n",
        "    model_name = 'bert-base-cased'\n",
        "    max_len = 128\n",
        "    hidden_size = 768\n",
        "\n",
        "    # Data preparation\n",
        "    test_fraction = 0.1\n",
        "    validation_fraction = 0.1\n",
        "    batch_size = 16\n",
        "    num_workers = 2\n",
        "    classes = ('quotes_of_death', 'quotes_of_science', 'quotes_of_humor', 'quotes_of_success', 'quotes_of_love')\n",
        "    tags_map = {cls:i for i,cls in enumerate(classes)}\n",
        "    logdir = 'logdir'\n",
        "\n",
        "    # Training\n",
        "    seed = 21\n",
        "    epochs = 5\n",
        "    learning_rate = 1e-6\n",
        "    num_classes = len(classes)\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "M9tpheI4Khay",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:44.721301Z",
          "iopub.execute_input": "2024-07-17T10:24:44.722012Z",
          "iopub.status.idle": "2024-07-17T10:24:44.728946Z",
          "shell.execute_reply.started": "2024-07-17T10:24:44.721980Z",
          "shell.execute_reply": "2024-07-17T10:24:44.727951Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "set_seed(Config.seed)"
      ],
      "metadata": {
        "id": "Ct9wTpKPKqP6",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:47.002031Z",
          "iopub.execute_input": "2024-07-17T10:24:47.002865Z",
          "iopub.status.idle": "2024-07-17T10:24:47.007857Z",
          "shell.execute_reply.started": "2024-07-17T10:24:47.002832Z",
          "shell.execute_reply": "2024-07-17T10:24:47.006780Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformers What Is It?**\n",
        "The [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper presented the Transformer model. Transformers are a new type of neural network aimed at **solving sequences with easy processing of long-range dependencies**.\n",
        "\n",
        "Unlike recurrent neural networks (**RNNs**), transformers do not process sequences in order. In a way, the transformer model is non-directional. For example, if the source data is text, they do not need to process the end of the sentence after processing the beginning. So, a transformer neural network can be parallelized and trained much faster.\n",
        "\n",
        "[The Transformer architecture](https://machinelearningmastery.com/the-transformer-model/) has an **encoder-decoder** structure. The **encoder** maps an input sequence `X`=$(x_1,x_2,..,x_n)$  into an abstract continuous representation `z`=$(z_1,z_2,..,z_n)$  that holds all the learned information of that input. The **decoder** then takes that continuous representation `z` and, step by step, generates an output sequence `Y`=$(y_1,y_2,..,y_m)$  of symbols one element at a time, consuming the previously generated symbols as additional input when generating the next.\n",
        "  \n",
        "\n",
        "## **Preprocessing & Tokenization**\n",
        "Before using your data in a model, data needs to be processed into an acceptable format. A model does not understand raw text, images or audio. So inputs need to be converted into numbers.\n",
        "\n",
        "The primary tool for processing textual data is a [tokenizer](https://huggingface.co/docs/transformers/master/en/main_classes/tokenizer). A tokenizer splits text into *tokens*, which are part of a fixed vocabulary. The tokens are converted into numbers, which are used to build tensors as input to a model.\n",
        "\n",
        "<img src=\"https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/ntbk_images/tokenization.png\">\n",
        "\n",
        "## **Embeddings**\n",
        "Tokens are converted into [embedding vectors](https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca) using a fixed representation like word2vec or any other. An embedding captures the input semantics by placing semantically similar inputs close together in the embedding space.\n",
        "\n",
        "## **Positional Encodings**\n",
        "Converting a sequence into tokenization, you lose the notion of order. The neural network cannot understand any order in a set of tokens. [The positional encoders](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/) receive inputs from the input embeddings layer and apply relative positional information. This layer outputs word vectors with positional information. In other words, it is the word‚Äôs meaning and its context in the sentence.\n",
        "\n",
        "<img src=\"https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/ntbk_images/positional_encoding.png\">\n",
        "\n",
        "## **Attention**\n",
        "LSTMs and RNNs present 3 problems:\n",
        "- Processing word by word inhibits parallelization\n",
        "- There is no explicit model of long and short-range dependencies\n",
        "- The model often forgets the content of distant positions in the sequence for long sentences\n",
        "\n",
        "So was created a technique to solve some of these problems by paying [attention](https://arxiv.org/pdf/1706.03762.pdf) to specific words. Neural networks can focus on the part of a subset of the information they are given. For example, imagine that you are in a large crowd of people. You can recognize your name being spoken by someone in a crowd, even if it should get lost in all the other noise. Your brain can focus on necessary things and filter out unnecessary information.\n",
        "\n",
        "Vanilla attention uses a linear combination of previously hidden vectors in the input sequence or a sentence in the case of a sequence-to-sequence model. This combination of hidden vectors is concatenated with the current word's vector and fed to the next layer of the model. [Here](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) you can find a more detailed explanation of attention with informative gifs.\n",
        "\n",
        "## **Self-Attention**\n",
        "[Self-attention](https://jalammar.github.io/illustrated-transformer/) is a new step in the attention technique. Instead of looking at prior hidden vectors when considering a word embedding, self-attention is a weighted combination of all other word embeddings.\n",
        "\n",
        "## **Multi-Headed Attention**\n",
        "[Multi-headed attention](https://jalammar.github.io/illustrated-transformer/) is a further innovation that gives the transformer greater power to encode multiple relationships for each word. The idea is that by repeating the self-attention mechanism multiple times, the model can learn to separate different kinds of useful semantic information into other channels.\n",
        "\n",
        "## **Outputs**\n",
        "\n",
        "- There are two output layers: a linear layer followed by a softmax layer. The linear layer performs a decompression task: it takes the final encoded representation for the output word. It turns it around into log-odds for each word in the recipient language's vocabulary. A softmax running on this then turns that into probabilities, and we take an `argmax` of that ‚Äî standard stuff for a language generation model.\n",
        "- The loss function is the cross-entropy of KL divergence.\n",
        "- As an optimization, beam search is also possible: take the top $ùëÅ$ most likely words and continue searching through the sentence with lookahead.\n",
        "\n",
        "## **NLP Tasks Transformers Can Solve**\n",
        "\n",
        "- ### MLM (Masked Language Modeling)\n",
        "    This transformer architecture involves masking part of the input and then learning a model to predict the missing tokens - essentially reconstructing the non-masked input. MLM is often used within pretraining tasks to allow models to learn textual patterns from unlabeled data.\n",
        "\n",
        "- ### NSP (Next Sentence Prediction)\n",
        "    In this transformer architecture, the model receives pairs of sentences as input and learns to predict if the second sentence in the pair is the subsequent sentence in the original document. During training, 50% of the inputs are a pair in which the second sentence is the subsequent sentence in the original document, while in the other 50%, a random sentence from the corpus is chosen as the second sentence. The assumption is that the random sentence will be disconnected from the first sentence.\n",
        "- ### SC (Sequence Classification)\n",
        "    Sequence classification is a DP technique in NLP to classify the type of text into a particular category. These categories depend on the type of task they perform. Examples include sentiment analysis, topic labelling, spam detection, and intent detection.\n",
        "- ### QA (Question Answering)\n",
        "    Question Answering aims to find the answer to a question given a question and an accompanying context. The predicted answer will be either a span of text from the context or an empty string (indicating the question cannot be answered from the context)."
      ],
      "metadata": {
        "id": "qLE4Xj4vYv1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Some BERT's model requirements for text preprocessing:\n",
        "- Add special tokens to separate sentences for doing classification.\n",
        "- Pass sequences using constant length.\n",
        "- Create an *attention mask* array consisting of 0s (pad token) and 1s (real token).\n",
        "\n",
        "We will use the transformers library, including prebuild tokenizers that help us process our text easily and quickly!\n",
        "\n",
        "Let's load a pre-trained [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer):\n",
        "\n",
        "> We will use a cased version of BERT and tokenizer - `bert-base-cased`."
      ],
      "metadata": {
        "id": "_kv4V0AguCsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[func] tokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(Config.model_name)"
      ],
      "metadata": {
        "id": "JD2-zL2orlaP",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:52.851756Z",
          "iopub.execute_input": "2024-07-17T10:24:52.852601Z",
          "iopub.status.idle": "2024-07-17T10:24:53.360143Z",
          "shell.execute_reply.started": "2024-07-17T10:24:52.852567Z",
          "shell.execute_reply": "2024-07-17T10:24:53.359344Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use some text to understand the tokenization process clearly:"
      ],
      "metadata": {
        "id": "U0-BPsLa3-Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'Success is not final; failure is not fatal: It is the courage to continue that counts.'"
      ],
      "metadata": {
        "id": "dcEASe3K39lE",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:55.362506Z",
          "iopub.execute_input": "2024-07-17T10:24:55.362875Z",
          "iopub.status.idle": "2024-07-17T10:24:55.367215Z",
          "shell.execute_reply.started": "2024-07-17T10:24:55.362845Z",
          "shell.execute_reply": "2024-07-17T10:24:55.366272Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some basic operations to convert our sample text to tokens and tokens to unique ids:"
      ],
      "metadata": {
        "id": "Gt7fpsLq4duV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(sample_text)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'Original sentence: {sample_text}')\n",
        "print(f'Tokenized sentence: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "metadata": {
        "id": "DsPMTvO641sl",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:24:57.605470Z",
          "iopub.execute_input": "2024-07-17T10:24:57.605846Z",
          "iopub.status.idle": "2024-07-17T10:24:57.612174Z",
          "shell.execute_reply.started": "2024-07-17T10:24:57.605818Z",
          "shell.execute_reply": "2024-07-17T10:24:57.611186Z"
        },
        "trusted": true,
        "outputId": "70ac797e-16cb-4e0b-fc85-3b1770ac840d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original sentence: Success is not final; failure is not fatal: It is the courage to continue that counts.\nTokenized sentence: ['Success', 'is', 'not', 'final', ';', 'failure', 'is', 'not', 'fatal', ':', 'It', 'is', 'the', 'courage', 'to', 'continue', 'that', 'counts', '.']\nToken IDs: [25911, 1110, 1136, 1509, 132, 4290, 1110, 1136, 11874, 131, 1135, 1110, 1103, 9163, 1106, 2760, 1115, 10664, 119]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Special Tokens\n",
        "\n",
        "BERT uses special tokens:\n",
        "\n",
        "- `[SEP]` - indicates the end of a sentence\n",
        "- `[CLS]` - is a special classification token, so we add this token to the start of each sentence.\n",
        "- `[PAD]` - is a special token for padding.\n",
        "- `[UNK]` - uses for tokens not appearing in the training vocabulary, so they should be replaced with a special token `[UNK]`, which stands for unknown token."
      ],
      "metadata": {
        "id": "oMgVoZNQ5NMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Token:{tokenizer.sep_token}, token id:{tokenizer.sep_token_id}')\n",
        "print(f'Token:{tokenizer.cls_token}, token id:{tokenizer.cls_token_id}')\n",
        "print(f'Token:{tokenizer.pad_token}, token id:{tokenizer.pad_token_id}')\n",
        "print(f'Token:{tokenizer.unk_token}, token id:{tokenizer.unk_token_id}')"
      ],
      "metadata": {
        "id": "xqWQ8CUR5D8f",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:00.059699Z",
          "iopub.execute_input": "2024-07-17T10:25:00.060490Z",
          "iopub.status.idle": "2024-07-17T10:25:00.065565Z",
          "shell.execute_reply.started": "2024-07-17T10:25:00.060459Z",
          "shell.execute_reply": "2024-07-17T10:25:00.064608Z"
        },
        "trusted": true,
        "outputId": "7e95fcac-a473-4a6e-a1af-976cb1b17bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Token:[SEP], token id:102\nToken:[CLS], token id:101\nToken:[PAD], token id:0\nToken:[UNK], token id:100\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All this can be combined using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method:"
      ],
      "metadata": {
        "id": "re34HGN_8qfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_text, # The sentence to be encoded\n",
        "  max_length=32, # Maximum length of a sentence\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False, # Don't return token type ids\n",
        "  padding='max_length', # Pad sentence to max length\n",
        "  return_attention_mask=True, # Generate the attention mask\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "# Let's get the sample text IDs and attention mask in tensor format\n",
        "input_ids = encoding['input_ids']\n",
        "attn_mask = encoding['attention_mask']\n",
        "ids_to_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "print(f'Input IDs: {input_ids}')\n",
        "print(f'Attention mask: {attn_mask}')\n",
        "print(f'Padded text length: {len(input_ids[0])}')"
      ],
      "metadata": {
        "id": "mxltI1mJ8aqq",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:03.820859Z",
          "iopub.execute_input": "2024-07-17T10:25:03.821729Z",
          "iopub.status.idle": "2024-07-17T10:25:03.832113Z",
          "shell.execute_reply.started": "2024-07-17T10:25:03.821674Z",
          "shell.execute_reply": "2024-07-17T10:25:03.831100Z"
        },
        "trusted": true,
        "outputId": "85470844-c2f7-4363-ef40-d87029112233"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Input IDs: tensor([[  101, 25911,  1110,  1136,  1509,   132,  4290,  1110,  1136, 11874,\n           131,  1135,  1110,  1103,  9163,  1106,  2760,  1115, 10664,   119,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]])\nAttention mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])\nPadded text length: 32\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Choosing Sequence Length**\n",
        "\n",
        "BERT model works with fixed-length sequences. So, we need to choose the max length we will use.\n",
        "\n",
        "**Excercise:** implement function `get_token_lens`\n",
        "\n",
        "\n",
        "- **Hint**: use `tokenizer.encode` to encode quote text with parameters `max_length=512` and `truncation=True`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6bPN4cWJE6Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[func] get_token_lens\n",
        "\n",
        "def get_token_lens(df):\n",
        "    \"\"\"\n",
        "    Calculates the token length of each quote in DataFrame\n",
        "\n",
        "    Arguments:\n",
        "    df -- Pandas DataFrame of quotes and their tags\n",
        "\n",
        "    Return:\n",
        "    token_lens -- 1-D np.array of integers that represents tokens lengths of quotes\n",
        "    \"\"\"\n",
        "\n",
        "    token_lens = []\n",
        "\n",
        "    ### START CODE HERE ### (‚âà 4 lines of code)\n",
        "    for i, quote in enumerate(df['quotes'], start=0):\n",
        "      #print(f'{i}, {quote}')\n",
        "      token_quote = tokenizer.encode(quote, max_length=512, truncation=True)\n",
        "      token_lens.append(len(token_quote))\n",
        "    return token_lens\n",
        "\n",
        "    ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "u_73uM8LD1fS",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:06.539410Z",
          "iopub.execute_input": "2024-07-17T10:25:06.540057Z",
          "iopub.status.idle": "2024-07-17T10:25:06.545964Z",
          "shell.execute_reply.started": "2024-07-17T10:25:06.540026Z",
          "shell.execute_reply": "2024-07-17T10:25:06.545069Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = data.iloc[:5].copy()\n",
        "sample_df_token_lens = get_token_lens(sample_df)\n",
        "print('Token lens: ', sample_df_token_lens)"
      ],
      "metadata": {
        "id": "mrqvqGZKFmJf",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:09.183074Z",
          "iopub.execute_input": "2024-07-17T10:25:09.183791Z",
          "iopub.status.idle": "2024-07-17T10:25:09.195119Z",
          "shell.execute_reply.started": "2024-07-17T10:25:09.183760Z",
          "shell.execute_reply": "2024-07-17T10:25:09.194117Z"
        },
        "trusted": true,
        "outputId": "460a48dc-f5da-4c48-a6e4-8d01c8a5a983"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Token lens:  [17, 68, 35, 26, 142]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**\n",
        "    \n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Token lens:</b></td>\n",
        "        <td>[ 17  68  35  26 142]</td>\n",
        "    </tr>\n",
        "    \n",
        "</table>"
      ],
      "metadata": {
        "id": "v5lhnO5dHQyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize tokens size distribution for all quotes:"
      ],
      "metadata": {
        "id": "72kTVv_VdxFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens_list = get_token_lens(data)\n",
        "\n",
        "sns.displot(token_lens_list, kind=\"kde\")\n",
        "plt.xlim([0, 512]);\n",
        "plt.xlabel('Token count');"
      ],
      "metadata": {
        "id": "ibxBLLRDG0K7",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:11.484125Z",
          "iopub.execute_input": "2024-07-17T10:25:11.484904Z",
          "iopub.status.idle": "2024-07-17T10:25:30.394555Z",
          "shell.execute_reply.started": "2024-07-17T10:25:11.484871Z",
          "shell.execute_reply": "2024-07-17T10:25:30.393593Z"
        },
        "trusted": true,
        "outputId": "8cbd2765-ddd8-4c4a-98e6-14a2dc28932b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x500 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to take the length of the power of two: 128. Most of the quotes seem to contain less than 128 tokens :) We will select those with a token length less than our chosen length from our dataset.\n",
        "\n",
        "**Excercise:** implement function `select_rows_with_required_token_lens`\n",
        "\n",
        "**Hints**:\n",
        "- create a new column `token_len` for `df`, where will be the token length for each quote\n",
        "- select rows with `token_len` less than `Config.max_len`. Don't forget to use `reset_index(drop=True)`\n"
      ],
      "metadata": {
        "id": "7UNPcCvsH9ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[func] select_rows_with_required_token_lens\n",
        "\n",
        "def select_rows_with_required_token_lens(df, max_len=Config.max_len):\n",
        "    \"\"\"\n",
        "    Selects rows from DataFrame with quotes token length less than max_len\n",
        "\n",
        "    Arguments:\n",
        "    df -- Pandas DataFrame of quotes and their tags\n",
        "\n",
        "    Return:\n",
        "    New DataFrame that has quotes tokens lengths less than max_len\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (‚âà3 lines of code)\n",
        "    df['token_len'] = [len(tokenizer.encode(i, max_length=512, truncation=True)) for i in df['quotes']]\n",
        "    df = df[df['token_len'] < Config.max_len].reset_index(drop=True)\n",
        "    return df\n",
        "    ### END CODE HERE ###"
      ],
      "metadata": {
        "id": "O40yxSMRG263",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:38.229886Z",
          "iopub.execute_input": "2024-07-17T10:25:38.230264Z",
          "iopub.status.idle": "2024-07-17T10:25:38.236872Z",
          "shell.execute_reply.started": "2024-07-17T10:25:38.230234Z",
          "shell.execute_reply": "2024-07-17T10:25:38.235922Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sample_df = select_rows_with_required_token_lens(sample_df)\n",
        "new_sample_df"
      ],
      "metadata": {
        "id": "3KxbGNxUV8Gv",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:40.592666Z",
          "iopub.execute_input": "2024-07-17T10:25:40.593169Z",
          "iopub.status.idle": "2024-07-17T10:25:40.611508Z",
          "shell.execute_reply.started": "2024-07-17T10:25:40.593132Z",
          "shell.execute_reply": "2024-07-17T10:25:40.610395Z"
        },
        "trusted": true,
        "outputId": "191a704b-950b-441f-93bc-595aec65f868"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 63,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              quotes              tag  \\\n0  To the well-organized mind, death is but the n...  quotes_of_death   \n1  I wish it need not have happened in my time,\" ...  quotes_of_death   \n2  I'm the one that's got to die when it's time f...  quotes_of_death   \n3  The fear of death follows from the fear of lif...  quotes_of_death   \n\n   token_len  \n0         17  \n1         68  \n2         35  \n3         26  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quotes</th>\n      <th>tag</th>\n      <th>token_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>To the well-organized mind, death is but the n...</td>\n      <td>quotes_of_death</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I wish it need not have happened in my time,\" ...</td>\n      <td>quotes_of_death</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm the one that's got to die when it's time f...</td>\n      <td>quotes_of_death</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The fear of death follows from the fear of lif...</td>\n      <td>quotes_of_death</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**\n",
        "    \n",
        "<table>\n",
        "<tbody>\n",
        "<tr style=\"height: 23px;\">\n",
        "<td style=\"height: 23px;\">&nbsp;</td>\n",
        "<td style=\"height: 23px;\">&nbsp;quotes</td>\n",
        "<td style=\"height: 23px;\">&nbsp;tag</td>\n",
        "<td style=\"height: 23px;\">&nbsp;token_len</td>\n",
        "</tr>\n",
        "<tr style=\"height: 23px;\">\n",
        "<td style=\"height: 23px;\">&nbsp;0</td>\n",
        "<td style=\"height: 23px;\">&nbsp;To the well-organized mind, death is but the n...</td>\n",
        "<td style=\"height: 23px;\">&nbsp;quotes_of_death</td>\n",
        "<td style=\"height: 23px;\">&nbsp;17</td>\n",
        "</tr>\n",
        "<tr style=\"height: 23px;\">\n",
        "<td style=\"height: 23px;\">&nbsp;1</td>\n",
        "<td style=\"height: 23px;\">&nbsp;I wish it need not have happened in my time,\" ...</td>\n",
        "<td style=\"height: 23px;\">&nbsp;quotes_of_death</td>\n",
        "<td style=\"height: 23px;\">&nbsp;68</td>\n",
        "</tr>\n",
        "<tr style=\"height: 23px;\">\n",
        "<td style=\"height: 23px;\">&nbsp;2</td>\n",
        "<td style=\"height: 23px;\">&nbsp;I'm the one that's got to die when it's time f...</td>\n",
        "<td style=\"height: 23px;\">&nbsp;quotes_of_death</td>\n",
        "<td style=\"height: 23px;\">&nbsp;35</td>\n",
        "</tr>\n",
        "<tr style=\"height: 23px;\">\n",
        "<td style=\"height: 23px;\">&nbsp;3</td>\n",
        "<td style=\"height: 23px;\">&nbsp;The fear of death follows from the fear of lif...</td>\n",
        "<td style=\"height: 23px;\">&nbsp;quotes_of_death</td>\n",
        "<td style=\"height: 23px;\">&nbsp;26</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>"
      ],
      "metadata": {
        "id": "Y_7p3rM0ZIps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train/Test/Val Split**"
      ],
      "metadata": {
        "id": "n9QOFaRlLtll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = select_rows_with_required_token_lens(data.copy())\n",
        "\n",
        "train_to_rest = Config.validation_fraction + Config.test_fraction\n",
        "test_to_valid = Config.validation_fraction / train_to_rest\n",
        "\n",
        "train_df, rest = train_test_split(new_data, random_state=Config.seed, test_size=train_to_rest)\n",
        "\n",
        "test_df, valid_df = train_test_split(rest, random_state=Config.seed,test_size=test_to_valid)\n",
        "\n",
        "print('Train data:', train_df.shape[0])\n",
        "print('Valid data:', valid_df.shape[0])\n",
        "print('Test data:', test_df.shape[0])"
      ],
      "metadata": {
        "id": "7N0TpGCiLujf",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:25:44.701323Z",
          "iopub.execute_input": "2024-07-17T10:25:44.701920Z",
          "iopub.status.idle": "2024-07-17T10:26:03.281108Z",
          "shell.execute_reply.started": "2024-07-17T10:25:44.701887Z",
          "shell.execute_reply": "2024-07-17T10:26:03.280057Z"
        },
        "trusted": true,
        "outputId": "7ef544b0-45ce-48e9-e2f4-91516bf85426"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train data: 10468\nValid data: 1309\nTest data: 1309\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset class and Dataloaders**\n",
        "We will define our custom PyTorch Dataset to load the quotes and their tags as one data sample.\n",
        "\n",
        "To implement PyTorch Dataset, we have to inherit from the generic PyTorch `Dataset` class and implement main and auxiliary functions:\n",
        "\n",
        "1. ` __init__`\n",
        "2. `__len__`\n",
        "3. `get_batch_tags`\n",
        "4. `get_batch_quotes`\n",
        "5. `__getitem__`\n",
        "\n",
        "### **Excercise:** implement functions:\n",
        "\n",
        "### 1.`__init__`\n",
        "The `__init__` method is responsible for initializing lists of tags and quotes for our dataset.\n",
        "\n",
        "**Hints**:\n",
        "- create an encoded list of dataset tags using dict `Config.tags_map`\n",
        "- create a tokens list of dataset quotes. Use the `tokenizer` we create earlier above with parameters:\n",
        "    - `padding='max_length'`\n",
        "    - `max_length = Config.max_len`\n",
        "    - `truncation=True`\n",
        "    - `return_tensors=\"pt\"`\n",
        "\n",
        "### 2.`__len__`\n",
        "This method is needed for the `Dataset` to understand the number of examples and for a `Dataloader` to calculate the number of batches. Find the number of tags.\n",
        "\n",
        "### 3.`get_batch_tags`\n",
        "This is a helper function for `__getitem__` to get a batch of tags with `idx`.\n",
        "\n",
        "**Hint**: the returned value must be `np.array` data type\n",
        "\n",
        "### 4.`get_batch_quotes`\n",
        "This is a helper function for `__getitem__` to get a batch of quotes with `idx`.\n",
        "\n",
        "### 5.`__getitem__`\n",
        "This method extracts a data sample by a numeric `idx`."
      ],
      "metadata": {
        "id": "kTviR_k7UMMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[cls] QuotesDataset\n",
        "\n",
        "class QuotesDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, max_len=Config.max_len):\n",
        "\n",
        "        ### START CODE HERE ### (‚âà6 lines of code)\n",
        "        self.tags = [Config.tags_map[tag] for tag in df['tag']]\n",
        "        self.quotes = [tokenizer(quote, padding='max_length', max_length=max_len, truncation=True, return_tensors=\"pt\") for quote in df['quotes']]\n",
        "\n",
        "    def __len__(self):\n",
        "        ### START CODE HERE ### (1 line of code)\n",
        "        return len(self.tags)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def get_batch_tags(self, idx):\n",
        "        # Get a batch of tags\n",
        "        ### START CODE HERE ### (1 line of code)\n",
        "        return np.array(self.tags[idx])\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def get_batch_quotes(self, idx):\n",
        "        # Get a batch of inputs\n",
        "        ### START CODE HERE ### (1 line of code)\n",
        "        return self.quotes[idx]\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ### START CODE HERE ### (2 lines of code)\n",
        "        batch_quotes = self.get_batch_quotes(idx)                #use get_batch_quotes\n",
        "        batch_y = self.get_batch_tags(idx)                        #use get_batch_tags\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return batch_quotes, batch_y"
      ],
      "metadata": {
        "id": "YQdU9VQ3ULhr",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:07.141778Z",
          "iopub.execute_input": "2024-07-17T10:26:07.142801Z",
          "iopub.status.idle": "2024-07-17T10:26:07.151129Z",
          "shell.execute_reply.started": "2024-07-17T10:26:07.142764Z",
          "shell.execute_reply": "2024-07-17T10:26:07.150196Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QuotesDS = QuotesDataset(sample_df, max_len=10)\n",
        "quote_data, tag = QuotesDS[3]\n",
        "\n",
        "print(\"Input_ids:\", quote_data['input_ids'])\n",
        "print(\"Token_type_ids:\", quote_data['token_type_ids'])\n",
        "print(\"Attention_mask:\", quote_data['attention_mask'])\n",
        "print(\"Edcoded tag:\", tag)"
      ],
      "metadata": {
        "id": "8-3bnCmY5GYG",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:11.830632Z",
          "iopub.execute_input": "2024-07-17T10:26:11.831741Z",
          "iopub.status.idle": "2024-07-17T10:26:11.846674Z",
          "shell.execute_reply.started": "2024-07-17T10:26:11.831700Z",
          "shell.execute_reply": "2024-07-17T10:26:11.845589Z"
        },
        "trusted": true,
        "outputId": "0dcfca95-a933-4551-c381-1f70a163d5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Input_ids: tensor([[ 101, 1109, 2945, 1104, 1473, 3226, 1121, 1103, 2945,  102]])\nToken_type_ids: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\nAttention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\nEdcoded tag: 0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**\n",
        "<table>\n",
        "<tr>\n",
        "    <td><b>Input_ids:</b></td>\n",
        "    <td>tensor([[ 101, 1109, 2945, 1104, 1473, 3226, 1121, 1103, 2945,  102]])</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td><b>Token_type_ids:</b></td>\n",
        "    <td>tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td><b>Attention_mask:</b></td>\n",
        "    <td>tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td><b>Edcoded tag:</b></td>\n",
        "    <td>0</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "0WFQyH7kAExo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loaders\n",
        "\n",
        "Here we will create datasets and dataloaders:"
      ],
      "metadata": {
        "id": "phtd6vKAVSsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = QuotesDataset(train_df)\n",
        "valid_data = QuotesDataset(valid_df)\n",
        "test_data = QuotesDataset(test_df)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=Config.batch_size, shuffle=True, num_workers=2)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=Config.batch_size, shuffle=False, num_workers=2)\n",
        "test_dataloader = DataLoader(test_data, batch_size=Config.batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "_DCxp3g6T-Do",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:14.294176Z",
          "iopub.execute_input": "2024-07-17T10:26:14.294759Z",
          "iopub.status.idle": "2024-07-17T10:26:29.214400Z",
          "shell.execute_reply.started": "2024-07-17T10:26:14.294713Z",
          "shell.execute_reply": "2024-07-17T10:26:29.213594Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the model class**\n",
        "\n",
        "Transformers library has a lot of helpers that make using BERT easy way. We could use [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) for our task classification, but we try to build our own quotes classifier.\n",
        "\n",
        "We'll use the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) as a basis and implement our own `nn.Module` sub-class with implementing `forward` and `__init__` for it.\n",
        "\n",
        "Our model will return a tuple with two variables. Let's understand all the shapes we will have during training: our input `x` is of size `(16, 128)`, we took a batch of `16` quotes, `128` tokens each, we will have an output `y` of size `(16, 128, 768)`, this is the BERTs final layer output for each token. Each token in each quote is represented using a vector of size `768`. According to BERT, the pooled output is of size `(16, 768)` is a summary of the content.\n",
        "\n",
        "We aim to take BERTs pooled output and apply a linear layer and a ReLU activation.\n",
        "\n",
        "**Excercise:** Your task will be to implement a `BertClassifier` and `forward` pass for it.\n",
        "\n",
        "**Hints:**\n",
        "- `__init__`:\n",
        "    * Instantiate a pretrained `bert-base-cased` pytorch model\n",
        "    * Add a dropout layer for some regularization with `p=0.5`\n",
        "    * Add FC layer for our output with `in_ch = num_classes` and `out_ch = hidden_size`\n",
        "    * Add `ReLU` activation function\n",
        "- `forward`:\n",
        "    * Return the raw output `pooled_output` of the last layer Bert model. Add parameter `return_dict=False`\n",
        "    * Use `self.dropout` on `pooled_output`\n",
        "    * Use `self.linear` layer\n",
        "    * Use `self.relu` activation function"
      ],
      "metadata": {
        "id": "85lSKtxIWiH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[cls] BertClassifier\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        ### START CODE HERE ### (‚âà4 lines of code)\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.linear = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "        ### START CODE HERE ### (‚âà4 line of code)\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        pooled_output = output[1]\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "lDWKbXnfWc7R",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:42.364531Z",
          "iopub.execute_input": "2024-07-17T10:26:42.365210Z",
          "iopub.status.idle": "2024-07-17T10:26:42.373187Z",
          "shell.execute_reply.started": "2024-07-17T10:26:42.365179Z",
          "shell.execute_reply": "2024-07-17T10:26:42.372109Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(Config.seed)\n",
        "Bert_Classifier = BertClassifier(Config.hidden_size, Config.num_classes)\n",
        "print('\\nOutput:', Bert_Classifier(input_ids, attn_mask)) # input_ids: [1,32], attn_mask:[1,32]\n",
        "print('Output shape:', Bert_Classifier(input_ids, attn_mask).shape)"
      ],
      "metadata": {
        "id": "m1fuQS2xv4BL",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:45.287704Z",
          "iopub.execute_input": "2024-07-17T10:26:45.288544Z",
          "iopub.status.idle": "2024-07-17T10:26:47.193132Z",
          "shell.execute_reply.started": "2024-07-17T10:26:45.288513Z",
          "shell.execute_reply": "2024-07-17T10:26:47.192187Z"
        },
        "trusted": true,
        "outputId": "df7c6aa6-cfaa-4416-ceee-ac2ebb9468f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nOutput: tensor([[0.0000, 0.6963, 0.3680, 0.0000, 0.6494]], grad_fn=<ReluBackward0>)\nOutput shape: torch.Size([1, 5])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**\n",
        "<table>\n",
        "<tr>\n",
        "    <td><b>Output:</b></td>\n",
        "    <td>tensor([ [ 0.0000, 0.6963, 0.3680, 0.0000, 0.6494 ] ], grad_fn='<'ReluBackward0'>')</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td><b>Output shape:</b></td>\n",
        "    <td>torch.Size([ 1, 5 ])</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "VMRIsYpX3Pwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the model**\n",
        "\n",
        "Next, we will define the train and validation loops separately and then combine them in the overall train function.\n",
        "\n",
        "We will compute two metrics:\n",
        "- loss\n",
        "- accuracy\n",
        "\n",
        "## Train Loop\n",
        "\n",
        "**Excercise:** define function `train` for training the model."
      ],
      "metadata": {
        "id": "QATgMF0fZKFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[func] train\n",
        "\n",
        "def train(model, optimizer, criterion, train_loader, device=Config.device):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc='Iterating over train data')\n",
        "\n",
        "    total_loss_train = 0\n",
        "    total_acc_train = 0\n",
        "\n",
        "    for train_input, train_label in pbar:\n",
        "\n",
        "        ### START CODE HERE ### (‚âà11 lines of code)\n",
        "        # pass to device\n",
        "        train_label = train_label.to(device)\n",
        "        mask = train_input['attention_mask'].squeeze(1).to(device)\n",
        "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        # forward\n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, train_label)                 #calculate loss\n",
        "        total_loss_train += batch_loss.item()                       # += loss\n",
        "\n",
        "        acc =  (output.argmax(dim=1) == train_label).sum().item()  #calculate accuracy\n",
        "        total_acc_train += acc                     # += acc\n",
        "\n",
        "        # optimize\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    return total_loss_train/ len(train_loader.dataset), total_acc_train/ len(train_loader.dataset)"
      ],
      "metadata": {
        "id": "fWzM5jdwZBWU",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:50.922343Z",
          "iopub.execute_input": "2024-07-17T10:26:50.923143Z",
          "iopub.status.idle": "2024-07-17T10:26:50.931827Z",
          "shell.execute_reply.started": "2024-07-17T10:26:50.923107Z",
          "shell.execute_reply": "2024-07-17T10:26:50.930747Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(Config.seed)\n",
        "model = BertClassifier(Config.hidden_size, Config.num_classes).to(Config.device)\n",
        "optimizer = Adam(model.parameters(), lr=Config.learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# we will use test_dataloader to speed up testing\n",
        "loss, acc = train(model, optimizer, criterion, test_dataloader)\n",
        "print(f'\\nTrain Loss: {loss: .3f} | Train Accuracy: {acc: .3f}')"
      ],
      "metadata": {
        "id": "299OfqWIcAsa",
        "execution": {
          "iopub.status.busy": "2024-07-17T10:26:54.128819Z",
          "iopub.execute_input": "2024-07-17T10:26:54.129162Z",
          "iopub.status.idle": "2024-07-17T10:27:21.848643Z",
          "shell.execute_reply.started": "2024-07-17T10:26:54.129137Z",
          "shell.execute_reply": "2024-07-17T10:27:21.847512Z"
        },
        "trusted": true,
        "outputId": "8326ba43-f481-41d0-e7fa-5298558604f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nIterating over train data:   0%|          | 0/82 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nIterating over train data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:25<00:00,  3.21it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nIterating over train data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:25<00:00,  3.17it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nTrain Loss:  0.105 | Train Accuracy:  0.189\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output should be around:**\n",
        "<table>\n",
        "<tr>\n",
        "    <td><b>Train Loss:</b></td>\n",
        "    <td>0.104</td>\n",
        "    <td><b>Train Accuracy:</b></td>\n",
        "    <td>0.213</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "LqNq7Z_acyrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation loop"
      ],
      "metadata": {
        "id": "pjE3PCaDfSqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION_FIELD[func] evaluate\n",
        "\n",
        "def evaluate(model, criterion, eval_loader, device=Config.device):\n",
        "    model.eval()\n",
        "\n",
        "    total_acc_val = 0\n",
        "    total_loss_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n",
        "        for val_input, val_label in pbar:\n",
        "\n",
        "            ### START CODE HERE ### (‚âà8 lines of code)\n",
        "            # pass to device\n",
        "            input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "            mask = val_input['attention_mask'].squeeze(1).to(device)\n",
        "            val_label = val_label.to(device)\n",
        "\n",
        "            # forward\n",
        "            outputs = model(input_id, mask)\n",
        "            loss = criterion(outputs, val_label)\n",
        "            total_loss_val += loss.item()\n",
        "\n",
        "            #predicted = torch.argmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_acc_val += (predicted == val_label).sum().item()\n",
        "\n",
        "    return total_loss_val/ len(eval_loader.dataset), total_acc_val/ len(eval_loader.dataset)"
      ],
      "metadata": {
        "id": "ws8I7YebccvE",
        "execution": {
          "iopub.status.busy": "2024-07-17T11:04:22.716003Z",
          "iopub.execute_input": "2024-07-17T11:04:22.716349Z",
          "iopub.status.idle": "2024-07-17T11:04:22.725050Z",
          "shell.execute_reply.started": "2024-07-17T11:04:22.716323Z",
          "shell.execute_reply": "2024-07-17T11:04:22.724123Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(Config.seed)\n",
        "model = BertClassifier(Config.hidden_size, Config.num_classes).to(Config.device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss, acc = evaluate(model, criterion, valid_dataloader)\n",
        "print(f'\\nEval Loss: {loss: .3f} | Eval Accuracy: {acc: .3f}')"
      ],
      "metadata": {
        "id": "4JbniIAWgJ-w",
        "execution": {
          "iopub.status.busy": "2024-07-17T11:04:24.836732Z",
          "iopub.execute_input": "2024-07-17T11:04:24.837642Z",
          "iopub.status.idle": "2024-07-17T11:04:35.963104Z",
          "shell.execute_reply.started": "2024-07-17T11:04:24.837608Z",
          "shell.execute_reply": "2024-07-17T11:04:35.961991Z"
        },
        "trusted": true,
        "outputId": "7d8ba89f-5a64-49fb-d960-259dfbb223e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nIterating over evaluation data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82/82 [00:09<00:00,  8.79it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEval Loss:  0.101 | Eval Accuracy:  0.211\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output should be around:**\n",
        "<table>\n",
        "<tr>\n",
        "    <td><b>Eval Loss:</b></td>\n",
        "    <td>0.101</td>\n",
        "    <td><b>Eval Accuracy:</b></td>\n",
        "    <td>0.211</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "1ZiYfKtJd_gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, optimizer, criterion, train_loader, valid_loader, device=Config.device, num_epochs=Config.epochs, logdir=Config.logdir):\n",
        "\n",
        "    history = defaultdict(list)\n",
        "    best_accuracy = 0\n",
        "\n",
        "    tb_writer = SummaryWriter(log_dir=logdir)\n",
        "    for e in range(num_epochs):\n",
        "\n",
        "        print(f'Epoch {e + 1}/{num_epochs}')\n",
        "\n",
        "        # train on training set\n",
        "        train_loss, train_acc = train(model, optimizer, criterion, train_loader, device=device)\n",
        "        # evaluate on validation set\n",
        "        val_loss, val_acc = evaluate(model, criterion, valid_loader, device=device)\n",
        "\n",
        "        print(f'\\nTrain Loss {train_loss: .3f} | Val Loss {val_loss: .3f}')\n",
        "        print(f'Train Accuracy {train_acc: .3f} | Val Accuracy {val_acc: .3f}')\n",
        "        print()\n",
        "\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        # Tensorboards Logging\n",
        "        tb_writer.add_scalar('Bert/Train Loss', train_loss, e)\n",
        "        tb_writer.add_scalar('Bert/Valid Loss', val_loss, e)\n",
        "        tb_writer.add_scalar('Bert/Train Accuracy', train_acc, e)\n",
        "        tb_writer.add_scalar('Bert/Valid Accuracy', val_acc, e)\n",
        "\n",
        "        if val_acc > best_accuracy:\n",
        "            torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "            best_accuracy = val_acc\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "x3yvQzYBghHY",
        "execution": {
          "iopub.status.busy": "2024-07-17T09:19:32.696871Z",
          "iopub.execute_input": "2024-07-17T09:19:32.697250Z",
          "iopub.status.idle": "2024-07-17T09:19:32.708068Z",
          "shell.execute_reply.started": "2024-07-17T09:19:32.697221Z",
          "shell.execute_reply": "2024-07-17T09:19:32.707108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train loss** after 5 epochs should be around ‚âà0.038 and **Accuracy** ‚âà 0.810.\n",
        "\n",
        "**Valid loss** after 5 epochs should be around ‚âà0.039 and **Accuracy** ‚âà 0.798.\n",
        "\n",
        "**Note:** you don't have to wait for the model to finish full training to submit the lab. We evaluate your code only in cells where we ask you to implement a function or a class."
      ],
      "metadata": {
        "id": "7kPGV4V_fL4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(Config.seed)\n",
        "model = BertClassifier(Config.hidden_size, Config.num_classes).to(Config.device)\n",
        "optimizer = Adam(model.parameters(), lr=Config.learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "history = train_loop(model, optimizer, criterion, train_dataloader, valid_dataloader)"
      ],
      "metadata": {
        "id": "UU9VLxsgjQ6N",
        "execution": {
          "iopub.status.busy": "2024-07-17T09:19:36.760590Z",
          "iopub.execute_input": "2024-07-17T09:19:36.760979Z"
        },
        "trusted": true,
        "outputId": "d655a2b7-3908-4109-e244-0ccdb88f8c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Iterating over train data:  11%|‚ñà         | 70/655 [00:22<03:08,  3.10it/s]",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to start TensorBoard in Google Colab run the following command\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=logdir"
      ],
      "metadata": {
        "id": "l1PN_c4h6pik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =  plt.subplots(2, 1, figsize=(10, 6))\n",
        "ax[0].plot(history['train_acc'], label='train accuracy')\n",
        "ax[0].plot(history['val_acc'], label='validation accuracy')\n",
        "ax[0].set_title('Accuracy')\n",
        "ax[0].legend()\n",
        "ax[1].plot(history['train_loss'], label='train loss')\n",
        "ax[1].plot(history['val_loss'], label='validation loss')\n",
        "ax[1].set_title('Losses')\n",
        "ax[1].legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzW1GgwILjEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the latest model\n",
        "model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "loss, acc = evaluate(model, criterion, test_dataloader)\n",
        "\n",
        "print(f'\\nTest Loss: {loss : .3f} | Test Accuracy {acc : .3f}')"
      ],
      "metadata": {
        "id": "h_gQ12CMqY8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output should be around:**\n",
        "<table>\n",
        "<tr>\n",
        "    <td><b>Test Loss:</b></td>\n",
        "    <td>0.036</td>\n",
        "    <td><b>Test Accuracy:</b></td>\n",
        "    <td>0.811</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "Du81omb1elp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting on Raw Text**\n",
        "\n",
        "Let's use our model to predict the quote tag of some raw text:"
      ],
      "metadata": {
        "id": "TFz1DuEDyfBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quote_text = \"Being deeply loved by someone gives you strength, while loving someone deeply gives you courage.\""
      ],
      "metadata": {
        "id": "K4b6LQbZyeiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the tokenizer to encode the text:"
      ],
      "metadata": {
        "id": "7QsX8fwHfYVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_quote = tokenizer.encode_plus(\n",
        "  quote_text,\n",
        "  max_length=Config.max_len,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  padding='max_length',\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt')"
      ],
      "metadata": {
        "id": "ewjvqLuPxxX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the predictions from our model:"
      ],
      "metadata": {
        "id": "rqguIZSufkA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = encoded_quote['input_ids'].to(Config.device)\n",
        "attention_mask = encoded_quote['attention_mask'].to(Config.device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {quote_text}')\n",
        "print(f'Quotes tag: {Config.classes[prediction]}')"
      ],
      "metadata": {
        "id": "u5a-_RfBzBnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What to do next**\n",
        "1. Submit your lab to `@DRU bot`.\n",
        "2. After you submit your lab, try experimenting with different token lengths and other hyperparameters. Also, you can try to use the [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) model for our task classification."
      ],
      "metadata": {
        "id": "JuNvejSAalhh"
      }
    }
  ]
}