<div align="center"><h1>DataRoot Labs</h1></div>
<div align="center"><h3>Practical Deep Learning with Pytorch</h3></div>

Course Modules
1. **Introduction to Deep Learning and Neural Networks**

What a Neural Network is mathematically.
How to implement Neural Networks in practice.
Topics covered:
Linear Algebra in Neural Networks
Hyperparameter Tuning
Regularization Techniques
Assessment: Knowledge test at the end of the module.

2. **Introduction to PyTorch**

Basics of building your first Neural Network.
Advanced autograd mechanics.
Assessment: Module test and practical application in two labs:
Creating, training, and evaluating neural networks.

3. **Convolutional Neural Networks**

Object Classification
Object Segmentation
Object Detection
Learn about state-of-the-art models:
YOLO_v3
ResNet
UNet
Assessment: Three labs, a Kaggle competition, and a test.

4. **Recurrent Neural Networks**

Various recurrent models:
Vanilla RNN
GRU
LSTM
Training approaches:
Many-to-One
Many-to-Many
Fixed Sequence Length
Variable Sequence Length
Projects:
Build a character-level RNN to generate classical music.
Solve the Human Activity Recognition dataset using several variations of RNNs.

5. **Autoencoders**

Mathematical theory behind Autoencoders.
Comparison with Principal Component Analysis.
Project: Train a denoising autoencoder on a real-world dataset.

6. **Generative Models**
Generative Adversarial Networks (GANs) are powerful models for generating new data:

Learn about various GANs:
Classic GAN
Wasserstein GAN
Progressive GAN
StyleGAN
Assessment: Two labs, a test, and a project to generate your own CryptoPunks.

7. **Attention & Transformers**
Learn about sequence-to-sequence models, attention mechanisms, and Transformer models:

Hands-on practice with:
Google's BERT
OpenAI's GPT-2
Assessment: Project and test on Transformer applications.

8. **Deploying PyTorch Models**

Introduction to TorchScript for creating serializable and optimizable models.
Use Fastformers for faster inference from Transformer models.